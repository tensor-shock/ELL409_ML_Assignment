{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80cc9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from libsvm.svm import *\n",
    "from libsvm.svmutil import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01801c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5668b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "file='2019MT10718.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a8323f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data taken from file\n",
    "data=np.genfromtxt(file,delimiter=',')\n",
    "#req_data=[x for x in data if x[25] in [2,9]]\n",
    "#data=np.array(req_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf110aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 26)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dbf37d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.38722621e+00,  1.97009422e+00, -8.17460450e-01,\n",
       "        -1.29818167e+00,  2.39521093e+00, -2.35403796e+00,\n",
       "        -3.51096983e-01, -5.28852616e-02,  7.44110312e-02,\n",
       "         6.07147942e-01, -7.68584287e-01,  1.54252683e+00,\n",
       "        -4.47242389e-01, -6.82445824e-01,  1.23664142e+00,\n",
       "        -2.51019539e-01, -4.24678678e-01,  4.40052452e-01,\n",
       "        -1.88528558e-01, -3.83373842e-01,  2.79958390e-01,\n",
       "        -6.06625594e-01,  1.79927038e-01, -1.33464930e+00,\n",
       "         1.50773861e+00,  4.00000000e+00],\n",
       "       [-3.55729353e+00, -4.62083801e-01, -5.06124749e-01,\n",
       "        -2.35078106e-01, -1.63767306e+00, -1.15296805e+00,\n",
       "         1.71849957e+00, -5.87456993e-01, -6.55865933e-01,\n",
       "         4.41835731e-01,  1.01131021e+00,  1.45832462e+00,\n",
       "        -3.07575607e-01, -4.16837000e-01, -2.38078528e-01,\n",
       "        -8.90623850e-01, -1.03257819e+00, -3.46826736e-01,\n",
       "         1.34602733e-01,  7.28830050e-02, -2.37428300e-03,\n",
       "         4.04252148e-01,  2.55372077e-01, -7.81495172e-02,\n",
       "        -3.82493853e-01,  1.00000000e+00],\n",
       "       [ 1.68543600e+00, -3.83887121e-01, -6.07305850e-01,\n",
       "         1.10359458e+00, -4.27697022e+00,  1.77107196e+00,\n",
       "         1.67430239e+00,  1.14527451e+00,  1.85319974e+00,\n",
       "         6.52323635e-01, -1.37105797e-01,  2.46280547e-01,\n",
       "         1.13784261e+00, -2.86499197e+00,  5.51501973e-01,\n",
       "         3.30185004e-02,  2.37143647e+00, -1.34238346e+00,\n",
       "         4.95896468e-01, -1.34655947e+00, -3.71554048e-01,\n",
       "        -2.22738784e-01, -1.25851428e+00, -3.31740879e-01,\n",
       "         1.22612872e+00,  0.00000000e+00],\n",
       "       [-1.54072267e+00, -2.62438359e+00,  7.97695824e-01,\n",
       "        -1.22337397e+00,  2.15870394e-01, -5.57237594e-01,\n",
       "        -1.16481327e+00, -1.94715102e-01,  6.43281498e-01,\n",
       "         1.55949942e+00,  2.38399648e-01,  2.70940945e-01,\n",
       "         9.70954339e-01, -1.98692540e+00, -6.45386426e-01,\n",
       "        -4.96550392e-01,  2.37962230e-01, -4.62343331e-01,\n",
       "        -2.01091084e-01,  1.29524337e+00,  5.21405852e-02,\n",
       "         8.84625510e-01, -4.97221627e-01,  5.88776239e-01,\n",
       "         5.61891037e-01,  8.00000000e+00],\n",
       "       [ 5.40968614e+00, -1.53864013e+00,  7.00385292e-01,\n",
       "        -7.64112238e-01, -1.98918502e+00, -8.15015042e-01,\n",
       "        -5.70229337e-01, -9.51795423e-01, -1.52200794e+00,\n",
       "         1.69272942e-01, -1.38310322e+00,  7.95742563e-03,\n",
       "        -9.69186021e-01,  6.91545050e-01, -1.49124830e+00,\n",
       "         4.27184453e-02, -9.81660148e-01,  1.03698634e+00,\n",
       "         3.36900291e-01, -5.55863597e-01,  5.44626192e-01,\n",
       "         1.88257390e-01, -8.42092452e-03, -2.15103391e-01,\n",
       "        -1.05591328e-01,  0.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f5729d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=data[:,:25]\n",
    "tdata=data[:,25:].flatten()\n",
    "#xdata=data[:,:10]\n",
    "\n",
    "#tdata=tdata.reshape(tdata.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5307d9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd61904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85c22cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.9% (2877/3000) (classification)\n",
      "--- 0.13894295692443848 seconds ---\n"
     ]
    }
   ],
   "source": [
    "model = svm_train(tdata, xdata)\n",
    "\n",
    "start_time = time.time()\n",
    "p_labs, p_acc, p_vals = svm_predict(tdata, xdata, model )\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a36cce6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Accuracy = 88.2667% (1324/1500) (classification)\n",
      "Accuracy = 88.2667% (1324/1500) (classification)\n",
      "88.26666666666667\n",
      "3\n",
      "Accuracy = 89% (890/1000) (classification)\n",
      "Accuracy = 89.1% (891/1000) (classification)\n",
      "Accuracy = 89.1% (891/1000) (classification)\n",
      "89.06666666666666\n",
      "4\n",
      "Accuracy = 90.2667% (677/750) (classification)\n",
      "Accuracy = 90.2667% (677/750) (classification)\n",
      "Accuracy = 90.1333% (676/750) (classification)\n",
      "Accuracy = 90.1333% (676/750) (classification)\n",
      "90.19999999999999\n",
      "5\n",
      "Accuracy = 90% (540/600) (classification)\n",
      "Accuracy = 89.6667% (538/600) (classification)\n",
      "Accuracy = 89.6667% (538/600) (classification)\n",
      "Accuracy = 89.6667% (538/600) (classification)\n",
      "Accuracy = 89.8333% (539/600) (classification)\n",
      "89.76666666666667\n",
      "6\n",
      "Accuracy = 90.4% (452/500) (classification)\n",
      "Accuracy = 89.8% (449/500) (classification)\n",
      "Accuracy = 89.6% (448/500) (classification)\n",
      "Accuracy = 89.4% (447/500) (classification)\n",
      "Accuracy = 89.2% (446/500) (classification)\n",
      "Accuracy = 89.2% (446/500) (classification)\n",
      "89.60000000000001\n",
      "7\n",
      "Accuracy = 90.4206% (387/428) (classification)\n",
      "Accuracy = 90.1869% (386/428) (classification)\n",
      "Accuracy = 90.1869% (386/428) (classification)\n",
      "Accuracy = 90.6542% (388/428) (classification)\n",
      "Accuracy = 90.8879% (389/428) (classification)\n",
      "Accuracy = 90.1869% (386/428) (classification)\n",
      "Accuracy = 90.1869% (386/428) (classification)\n",
      "90.38718291054738\n",
      "8\n",
      "Accuracy = 90.9333% (341/375) (classification)\n",
      "Accuracy = 89.8667% (337/375) (classification)\n",
      "Accuracy = 89.8667% (337/375) (classification)\n",
      "Accuracy = 90.4% (339/375) (classification)\n",
      "Accuracy = 90.4% (339/375) (classification)\n",
      "Accuracy = 90.1333% (338/375) (classification)\n",
      "Accuracy = 89.8667% (337/375) (classification)\n",
      "Accuracy = 89.8667% (337/375) (classification)\n",
      "90.16666666666666\n",
      "9\n",
      "Accuracy = 90.991% (303/333) (classification)\n",
      "Accuracy = 90.3904% (301/333) (classification)\n",
      "Accuracy = 90.6907% (302/333) (classification)\n",
      "Accuracy = 90.0901% (300/333) (classification)\n",
      "Accuracy = 90.0901% (300/333) (classification)\n",
      "Accuracy = 90.0901% (300/333) (classification)\n",
      "Accuracy = 89.4895% (298/333) (classification)\n",
      "Accuracy = 89.7898% (299/333) (classification)\n",
      "Accuracy = 90.3904% (301/333) (classification)\n",
      "90.22355689022356\n",
      "10\n",
      "Accuracy = 91.3333% (274/300) (classification)\n",
      "Accuracy = 90% (270/300) (classification)\n",
      "Accuracy = 90% (270/300) (classification)\n",
      "Accuracy = 90.3333% (271/300) (classification)\n",
      "Accuracy = 90% (270/300) (classification)\n",
      "Accuracy = 90.3333% (271/300) (classification)\n",
      "Accuracy = 89.3333% (268/300) (classification)\n",
      "Accuracy = 89.6667% (269/300) (classification)\n",
      "Accuracy = 90% (270/300) (classification)\n",
      "Accuracy = 89.3333% (268/300) (classification)\n",
      "90.03333333333333\n",
      "11\n",
      "Accuracy = 92.2794% (251/272) (classification)\n",
      "Accuracy = 90.8088% (247/272) (classification)\n",
      "Accuracy = 91.5441% (249/272) (classification)\n",
      "Accuracy = 90.0735% (245/272) (classification)\n",
      "Accuracy = 88.9706% (242/272) (classification)\n",
      "Accuracy = 89.3382% (243/272) (classification)\n",
      "Accuracy = 89.7059% (244/272) (classification)\n",
      "Accuracy = 90.0735% (245/272) (classification)\n",
      "Accuracy = 88.9706% (242/272) (classification)\n",
      "Accuracy = 89.7059% (244/272) (classification)\n",
      "Accuracy = 89.3382% (243/272) (classification)\n",
      "90.07352941176472\n",
      "12\n",
      "Accuracy = 92.8% (232/250) (classification)\n",
      "Accuracy = 92% (230/250) (classification)\n",
      "Accuracy = 92% (230/250) (classification)\n",
      "Accuracy = 90.8% (227/250) (classification)\n",
      "Accuracy = 90.4% (226/250) (classification)\n",
      "Accuracy = 89.2% (223/250) (classification)\n",
      "Accuracy = 89.2% (223/250) (classification)\n",
      "Accuracy = 89.6% (224/250) (classification)\n",
      "Accuracy = 89.2% (223/250) (classification)\n",
      "Accuracy = 89.6% (224/250) (classification)\n",
      "Accuracy = 89.6% (224/250) (classification)\n",
      "Accuracy = 90.4% (226/250) (classification)\n",
      "90.40000000000002\n",
      "13\n",
      "Accuracy = 92.1739% (212/230) (classification)\n",
      "Accuracy = 92.1739% (212/230) (classification)\n",
      "Accuracy = 93.0435% (214/230) (classification)\n",
      "Accuracy = 91.7391% (211/230) (classification)\n",
      "Accuracy = 90.8696% (209/230) (classification)\n",
      "Accuracy = 91.3043% (210/230) (classification)\n",
      "Accuracy = 89.1304% (205/230) (classification)\n",
      "Accuracy = 88.6957% (204/230) (classification)\n",
      "Accuracy = 89.5652% (206/230) (classification)\n",
      "Accuracy = 90% (207/230) (classification)\n",
      "Accuracy = 89.5652% (206/230) (classification)\n",
      "Accuracy = 89.5652% (206/230) (classification)\n",
      "Accuracy = 89.5652% (206/230) (classification)\n",
      "90.5685618729097\n",
      "14\n",
      "Accuracy = 92.9907% (199/214) (classification)\n",
      "Accuracy = 91.5888% (196/214) (classification)\n",
      "Accuracy = 92.5234% (198/214) (classification)\n",
      "Accuracy = 92.5234% (198/214) (classification)\n",
      "Accuracy = 91.5888% (196/214) (classification)\n",
      "Accuracy = 91.1215% (195/214) (classification)\n",
      "Accuracy = 90.6542% (194/214) (classification)\n",
      "Accuracy = 89.2523% (191/214) (classification)\n",
      "Accuracy = 89.2523% (191/214) (classification)\n",
      "Accuracy = 89.7196% (192/214) (classification)\n",
      "Accuracy = 89.7196% (192/214) (classification)\n",
      "Accuracy = 89.7196% (192/214) (classification)\n",
      "Accuracy = 89.7196% (192/214) (classification)\n",
      "Accuracy = 89.7196% (192/214) (classification)\n",
      "90.72096128170895\n",
      "15\n",
      "Accuracy = 93% (186/200) (classification)\n",
      "Accuracy = 93% (186/200) (classification)\n",
      "Accuracy = 93% (186/200) (classification)\n",
      "Accuracy = 92.5% (185/200) (classification)\n",
      "Accuracy = 92% (184/200) (classification)\n",
      "Accuracy = 92% (184/200) (classification)\n",
      "Accuracy = 91% (182/200) (classification)\n",
      "Accuracy = 89% (178/200) (classification)\n",
      "Accuracy = 88.5% (177/200) (classification)\n",
      "Accuracy = 89.5% (179/200) (classification)\n",
      "Accuracy = 90.5% (181/200) (classification)\n",
      "Accuracy = 89% (178/200) (classification)\n",
      "Accuracy = 89.5% (179/200) (classification)\n",
      "Accuracy = 89.5% (179/200) (classification)\n",
      "Accuracy = 89% (178/200) (classification)\n",
      "90.73333333333333\n",
      "16\n",
      "Accuracy = 92.5134% (173/187) (classification)\n",
      "Accuracy = 93.0481% (174/187) (classification)\n",
      "Accuracy = 93.0481% (174/187) (classification)\n",
      "Accuracy = 92.5134% (173/187) (classification)\n",
      "Accuracy = 92.5134% (173/187) (classification)\n",
      "Accuracy = 91.4439% (171/187) (classification)\n",
      "Accuracy = 90.3743% (169/187) (classification)\n",
      "Accuracy = 90.9091% (170/187) (classification)\n",
      "Accuracy = 88.7701% (166/187) (classification)\n",
      "Accuracy = 88.7701% (166/187) (classification)\n",
      "Accuracy = 88.7701% (166/187) (classification)\n",
      "Accuracy = 88.2353% (165/187) (classification)\n",
      "Accuracy = 89.3048% (167/187) (classification)\n",
      "Accuracy = 89.3048% (167/187) (classification)\n",
      "Accuracy = 89.3048% (167/187) (classification)\n",
      "Accuracy = 89.3048% (167/187) (classification)\n",
      "90.50802139037434\n",
      "17\n",
      "Accuracy = 93.1818% (164/176) (classification)\n",
      "Accuracy = 92.6136% (163/176) (classification)\n",
      "Accuracy = 93.1818% (164/176) (classification)\n",
      "Accuracy = 91.4773% (161/176) (classification)\n",
      "Accuracy = 92.0455% (162/176) (classification)\n",
      "Accuracy = 91.4773% (161/176) (classification)\n",
      "Accuracy = 90.3409% (159/176) (classification)\n",
      "Accuracy = 90.9091% (160/176) (classification)\n",
      "Accuracy = 88.6364% (156/176) (classification)\n",
      "Accuracy = 88.6364% (156/176) (classification)\n",
      "Accuracy = 89.2045% (157/176) (classification)\n",
      "Accuracy = 88.6364% (156/176) (classification)\n",
      "Accuracy = 88.6364% (156/176) (classification)\n",
      "Accuracy = 89.7727% (158/176) (classification)\n",
      "Accuracy = 89.2045% (157/176) (classification)\n",
      "Accuracy = 88.6364% (156/176) (classification)\n",
      "Accuracy = 90.3409% (159/176) (classification)\n",
      "90.40775401069517\n",
      "18\n",
      "Accuracy = 93.3735% (155/166) (classification)\n",
      "Accuracy = 93.3735% (155/166) (classification)\n",
      "Accuracy = 93.3735% (155/166) (classification)\n",
      "Accuracy = 92.1687% (153/166) (classification)\n",
      "Accuracy = 92.7711% (154/166) (classification)\n",
      "Accuracy = 92.7711% (154/166) (classification)\n",
      "Accuracy = 90.9639% (151/166) (classification)\n",
      "Accuracy = 90.9639% (151/166) (classification)\n",
      "Accuracy = 87.9518% (146/166) (classification)\n",
      "Accuracy = 87.3494% (145/166) (classification)\n",
      "Accuracy = 89.1566% (148/166) (classification)\n",
      "Accuracy = 87.9518% (146/166) (classification)\n",
      "Accuracy = 88.5542% (147/166) (classification)\n",
      "Accuracy = 89.759% (149/166) (classification)\n",
      "Accuracy = 88.5542% (147/166) (classification)\n",
      "Accuracy = 90.3614% (150/166) (classification)\n",
      "Accuracy = 89.759% (149/166) (classification)\n",
      "Accuracy = 89.759% (149/166) (classification)\n",
      "90.49531459170012\n",
      "19\n",
      "Accuracy = 93.6306% (147/157) (classification)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.2675% (148/157) (classification)\n",
      "Accuracy = 92.9936% (146/157) (classification)\n",
      "Accuracy = 92.9936% (146/157) (classification)\n",
      "Accuracy = 92.3567% (145/157) (classification)\n",
      "Accuracy = 92.9936% (146/157) (classification)\n",
      "Accuracy = 91.7197% (144/157) (classification)\n",
      "Accuracy = 90.4459% (142/157) (classification)\n",
      "Accuracy = 87.8981% (138/157) (classification)\n",
      "Accuracy = 87.8981% (138/157) (classification)\n",
      "Accuracy = 89.172% (140/157) (classification)\n",
      "Accuracy = 87.8981% (138/157) (classification)\n",
      "Accuracy = 89.172% (140/157) (classification)\n",
      "Accuracy = 89.172% (140/157) (classification)\n",
      "Accuracy = 89.172% (140/157) (classification)\n",
      "Accuracy = 90.4459% (142/157) (classification)\n",
      "Accuracy = 90.4459% (142/157) (classification)\n",
      "Accuracy = 91.7197% (144/157) (classification)\n",
      "Accuracy = 89.8089% (141/157) (classification)\n",
      "90.7475695608448\n",
      "20\n",
      "Accuracy = 93.3333% (140/150) (classification)\n",
      "Accuracy = 94% (141/150) (classification)\n",
      "Accuracy = 92.6667% (139/150) (classification)\n",
      "Accuracy = 92.6667% (139/150) (classification)\n",
      "Accuracy = 92% (138/150) (classification)\n",
      "Accuracy = 92.6667% (139/150) (classification)\n",
      "Accuracy = 91.3333% (137/150) (classification)\n",
      "Accuracy = 90% (135/150) (classification)\n",
      "Accuracy = 87.3333% (131/150) (classification)\n",
      "Accuracy = 88% (132/150) (classification)\n",
      "Accuracy = 88.6667% (133/150) (classification)\n",
      "Accuracy = 88.6667% (133/150) (classification)\n",
      "Accuracy = 89.3333% (134/150) (classification)\n",
      "Accuracy = 89.3333% (134/150) (classification)\n",
      "Accuracy = 90% (135/150) (classification)\n",
      "Accuracy = 90.6667% (136/150) (classification)\n",
      "Accuracy = 90.6667% (136/150) (classification)\n",
      "Accuracy = 90% (135/150) (classification)\n",
      "Accuracy = 89.3333% (134/150) (classification)\n",
      "Accuracy = 87.3333% (131/150) (classification)\n",
      "90.39999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajarshidas/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "err=[]\n",
    "min_lim=2\n",
    "max_lim=21\n",
    "for k in range(min_lim,max_lim):\n",
    "    #k batch cross val (k taken to be 6 gives good result)\n",
    "    data_points_total=xdata.shape[0]\n",
    "    val_set_size=int(data_points_total/k)\n",
    "    train_set_size=data_points_total-val_set_size\n",
    "    accuracy=[]\n",
    "    print(k)\n",
    "    for val_step in range(k):\n",
    "        test_begin_index=k*val_step\n",
    "        test_end_index=min(test_begin_index+val_set_size,data_points_total)\n",
    "        xtrain=np.append(xdata[:test_begin_index][:],xdata[test_end_index:][:])\n",
    "        ttrain=np.append(tdata[:test_begin_index],tdata[test_end_index:])\n",
    "        r=ttrain.shape[0]\n",
    "        c=int(xtrain.shape[0]/r)\n",
    "        xtrain=xtrain.reshape(r,c)\n",
    "        xvalid=xdata[test_begin_index:test_end_index]\n",
    "        tvalid=tdata[test_begin_index:test_end_index]\n",
    "        #print(xvalid.shape,xtrain.shape)\n",
    "        #print(tvalid)\n",
    "        model = svm_train(ttrain, xtrain)\n",
    "        p_labs, p_acc, p_vals = svm_predict(tvalid, xvalid, model )\n",
    "        accuracy.append(p_acc[0])\n",
    "    print(np.mean(accuracy))\n",
    "    err.append(np.mean(accuracy))\n",
    "#best fit poly after cross_validation\n",
    "xp=[i for i in range(min_lim,max_lim)]\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(xp,err,marker='o',label='accuracy')\n",
    "plt.title('accuracy vs number of cross-validation batches')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e3e48eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93% (186/200) (classification)\n",
      "--- 0.009341001510620117 seconds ---\n",
      "Accuracy = 93% (186/200) (classification)\n",
      "--- 0.009147167205810547 seconds ---\n",
      "Accuracy = 93% (186/200) (classification)\n",
      "--- 0.00946497917175293 seconds ---\n",
      "Accuracy = 92.5% (185/200) (classification)\n",
      "--- 0.009209871292114258 seconds ---\n",
      "Accuracy = 92% (184/200) (classification)\n",
      "--- 0.009240865707397461 seconds ---\n",
      "Accuracy = 92% (184/200) (classification)\n",
      "--- 0.009195089340209961 seconds ---\n",
      "Accuracy = 91% (182/200) (classification)\n",
      "--- 0.009361982345581055 seconds ---\n",
      "Accuracy = 89% (178/200) (classification)\n",
      "--- 0.00927114486694336 seconds ---\n",
      "Accuracy = 88.5% (177/200) (classification)\n",
      "--- 0.009380817413330078 seconds ---\n",
      "Accuracy = 89.5% (179/200) (classification)\n",
      "--- 0.009027957916259766 seconds ---\n",
      "Accuracy = 90.5% (181/200) (classification)\n",
      "--- 0.009443998336791992 seconds ---\n",
      "Accuracy = 89% (178/200) (classification)\n",
      "--- 0.009217023849487305 seconds ---\n",
      "Accuracy = 89.5% (179/200) (classification)\n",
      "--- 0.009348154067993164 seconds ---\n",
      "Accuracy = 89.5% (179/200) (classification)\n",
      "--- 0.009169816970825195 seconds ---\n",
      "Accuracy = 89% (178/200) (classification)\n",
      "--- 0.009453058242797852 seconds ---\n",
      "Number of batches 15\n",
      "Number of features are 10\n",
      "final accuracy 90.73333333333333\n"
     ]
    }
   ],
   "source": [
    "#12 batch cross val \n",
    "data_points_total=xdata.shape[0]\n",
    "k=15\n",
    "val_set_size=int(data_points_total/k)\n",
    "train_set_size=data_points_total-val_set_size\n",
    "accuracy=[]\n",
    "for val_step in range(k):\n",
    "    test_begin_index=k*val_step\n",
    "    test_end_index=min(test_begin_index+val_set_size,data_points_total)\n",
    "    xtrain=np.append(xdata[:test_begin_index][:],xdata[test_end_index:][:])\n",
    "    ttrain=np.append(tdata[:test_begin_index],tdata[test_end_index:])\n",
    "    r=ttrain.shape[0]\n",
    "    c=int(xtrain.shape[0]/r)\n",
    "    xtrain=xtrain.reshape(r,c)\n",
    "    xvalid=xdata[test_begin_index:test_end_index]\n",
    "    tvalid=tdata[test_begin_index:test_end_index]\n",
    "    #print(xvalid.shape,xtrain.shape)\n",
    "    #print(tvalid)\n",
    "    model = svm_train(ttrain, xtrain,'-t 2'  )\n",
    "    start_time = time.time()\n",
    "    p_labs, p_acc, p_vals = svm_predict(tvalid, xvalid, model )\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    accuracy.append(p_acc[0])\n",
    "\n",
    "print('Number of batches',k)\n",
    "print('Number of features are', 10)\n",
    "#print('gamma value is',2)\n",
    "print('final accuracy',np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fabecd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021465063095092773 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020743846893310547 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021234989166259766 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020733118057250977 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021130084991455078 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02097916603088379 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.020964860916137695 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021164894104003906 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021537065505981445 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021725177764892578 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02180027961730957 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021976947784423828 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02130293846130371 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.022440195083618164 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02293992042541504 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02503824234008789 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.022655963897705078 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02292799949645996 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.023647785186767578 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.022828102111816406 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02408885955810547 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021614789962768555 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.030124902725219727 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02292799949645996 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02130722999572754 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020678043365478516 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02131485939025879 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020730018615722656 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.020944833755493164 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.023432254791259766 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.022077083587646484 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.022101163864135742 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.028933048248291016 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.022289276123046875 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02235889434814453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.022428274154663086 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666664\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02112102508544922 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021044015884399414 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020857810974121094 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020888805389404297 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.020977258682250977 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021244049072265625 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02102518081665039 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02097797393798828 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02137613296508789 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02120804786682129 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021771907806396484 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021132946014404297 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021278858184814453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021373987197875977 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02126288414001465 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020713090896606445 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021123170852661133 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.020785808563232422 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.0211789608001709 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021197080612182617 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021592140197753906 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021528959274291992 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021374940872192383 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021435022354125977 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021226167678833008 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.0210268497467041 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020979881286621094 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021074771881103516 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.02112889289855957 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02191901206970215 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021284103393554688 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021620988845825195 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021457910537719727 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021131038665771484 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021512985229492188 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020907163619995117 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021119117736816406 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021152019500732422 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020954132080078125 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020930051803588867 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.02107691764831543 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.020884037017822266 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021355152130126953 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02126288414001465 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021433115005493164 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02095508575439453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02140069007873535 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021422863006591797 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021237850189208984 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.022984981536865234 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021218061447143555 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02110004425048828 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021049976348876953 seconds ---\n",
      "-t 3 -g 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02114105224609375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021632909774780273 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02089071273803711 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021251678466796875 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021234989166259766 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021188974380493164 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021422147750854492 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021059751510620117 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02089715003967285 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02090597152709961 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02105116844177246 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021136760711669922 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.0211331844329834 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021231651306152344 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021219730377197266 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021364927291870117 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021166086196899414 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021419048309326172 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02214193344116211 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666675\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02396082878112793 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02255725860595703 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.023139238357543945 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.024927139282226562 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.0220947265625 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02216506004333496 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021651268005371094 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02103400230407715 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02128314971923828 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02160191535949707 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021317720413208008 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02122807502746582 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021239042282104492 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020843982696533203 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02087092399597168 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020876646041870117 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.0208740234375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02107977867126465 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021278858184814453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021046876907348633 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021238088607788086 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02103400230407715 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021062135696411133 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.0212099552154541 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02108478546142578 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021050214767456055 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020944833755493164 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02104020118713379 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.0209808349609375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021198034286499023 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.020975112915039062 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02099776268005371 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.020963191986083984 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.0210878849029541 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.020969867706298828 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021221160888671875 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021297931671142578 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021568775177001953 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02140974998474121 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021252870559692383 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021384000778198242 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021178722381591797 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.022124052047729492 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021095991134643555 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021362781524658203 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.020947933197021484 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.0211031436920166 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02144002914428711 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021032094955444336 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020945072174072266 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020815134048461914 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02089095115661621 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.020978212356567383 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021959304809570312 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.022318124771118164 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021530866622924805 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.022299766540527344 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021973133087158203 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02204418182373047 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021938800811767578 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.0214078426361084 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021043062210083008 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020975828170776367 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02101612091064453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021205902099609375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021166086196899414 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02134990692138672 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021118879318237305 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.0211789608001709 seconds ---\n",
      "-t 3 -g 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02089381217956543 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02129364013671875 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021625995635986328 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021580934524536133 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021129131317138672 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02117609977722168 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021192073822021484 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021795988082885742 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021803855895996094 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02123093605041504 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021225929260253906 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.022222042083740234 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02143716812133789 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021079063415527344 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021379947662353516 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02137923240661621 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02095508575439453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02108311653137207 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021138906478881836 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.02112293243408203 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021295785903930664 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021116971969604492 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02105426788330078 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021265029907226562 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021214008331298828 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021378040313720703 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021513938903808594 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02113509178161621 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020998001098632812 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021043062210083008 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021070003509521484 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021014928817749023 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02136516571044922 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.022005081176757812 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021214962005615234 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021008014678955078 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021168231964111328 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021360158920288086 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02133488655090332 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02103900909423828 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021187782287597656 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021134138107299805 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02120184898376465 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021208763122558594 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021518945693969727 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.0216372013092041 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.0212709903717041 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02112722396850586 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021278858184814453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021320104598999023 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02202606201171875 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02147197723388672 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021132707595825195 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021148204803466797 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020936965942382812 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021188020706176758 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021008014678955078 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021239042282104492 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021090030670166016 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02114701271057129 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021209001541137695 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02121877670288086 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02130413055419922 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021090984344482422 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021134138107299805 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020898818969726562 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020931005477905273 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021099090576171875 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02099776268005371 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02114391326904297 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021210908889770508 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021298885345458984 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02129197120666504 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.0212857723236084 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021252155303955078 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021270036697387695 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02108001708984375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021008014678955078 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020990848541259766 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.020956039428710938 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02114081382751465 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.020901918411254883 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02099299430847168 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02114105224609375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02239990234375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02216196060180664 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021485090255737305 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021231889724731445 seconds ---\n",
      "-t 3 -g 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02089405059814453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021038055419921875 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020968198776245117 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021600961685180664 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021352052688598633 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02162003517150879 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02163100242614746 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021561861038208008 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02151799201965332 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021239042282104492 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021651268005371094 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021924734115600586 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.021107912063598633 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02094268798828125 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021934986114501953 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.02108597755432129 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021174192428588867 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021199941635131836 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.020982980728149414 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021059036254882812 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021064043045043945 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.0209810733795166 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021247148513793945 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02130913734436035 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020887136459350586 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02100992202758789 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021123170852661133 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.020945072174072266 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02111220359802246 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021019935607910156 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02112102508544922 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021220922470092773 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021187782287597656 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02131795883178711 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02162027359008789 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021625280380249023 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.022994041442871094 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021132946014404297 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021687030792236328 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021465063095092773 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021389007568359375 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02126622200012207 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021503925323486328 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021064281463623047 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02111220359802246 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021179914474487305 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021641016006469727 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021114826202392578 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02130603790283203 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020945072174072266 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021273136138916016 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021297216415405273 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02113819122314453 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02105998992919922 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021077871322631836 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021214962005615234 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021098852157592773 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021062850952148438 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021399974822998047 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021095991134643555 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.02089071273803711 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.020988941192626953 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02092599868774414 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.02094292640686035 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.02167510986328125 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.02108478546142578 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.02201700210571289 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.02147674560546875 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02126598358154297 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.02124476432800293 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021488189697265625 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.02115607261657715 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.020936965942382812 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02126002311706543 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02092123031616211 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.021168947219848633 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021220684051513672 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021152019500732422 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021147966384887695 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021422147750854492 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021184682846069336 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021249055862426758 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021296262741088867 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.16666666666667\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021371126174926758 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.2% (63/250) (classification)\n",
      "--- 0.022311925888061523 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.02101874351501465 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021090984344482422 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 25.6% (64/250) (classification)\n",
      "--- 0.02114105224609375 seconds ---\n",
      "-t 3 -g 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 28.4% (71/250) (classification)\n",
      "--- 0.021808862686157227 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26% (65/250) (classification)\n",
      "--- 0.021252870559692383 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 28.8% (72/250) (classification)\n",
      "--- 0.021018028259277344 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.8% (67/250) (classification)\n",
      "--- 0.021318912506103516 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.8% (62/250) (classification)\n",
      "--- 0.021265029907226562 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 24.4% (61/250) (classification)\n",
      "--- 0.021007776260375977 seconds ---\n",
      "-t 3 -g 5\n",
      "Accuracy = 26.4% (66/250) (classification)\n",
      "--- 0.021322011947631836 seconds ---\n",
      "Number of batches 12\n",
      "final accuracy 26.166666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajarshidas/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#15 batch cross val \n",
    "data_points_total=xdata.shape[0]\n",
    "k=12\n",
    "val_set_size=int(data_points_total/k)\n",
    "train_set_size=data_points_total-val_set_size\n",
    "accuracy=[]\n",
    "vals=[i for i in range(0,30)]\n",
    "acc_val=[]\n",
    "for i in vals:\n",
    "    for val_step in range(k):\n",
    "        test_begin_index=k*val_step\n",
    "        test_end_index=min(test_begin_index+val_set_size,data_points_total)\n",
    "        xtrain=np.append(xdata[:test_begin_index][:],xdata[test_end_index:][:])\n",
    "        ttrain=np.append(tdata[:test_begin_index],tdata[test_end_index:])\n",
    "        r=ttrain.shape[0]\n",
    "        c=int(xtrain.shape[0]/r)\n",
    "        xtrain=xtrain.reshape(r,c)\n",
    "        xvalid=xdata[test_begin_index:test_end_index]\n",
    "        tvalid=tdata[test_begin_index:test_end_index]\n",
    "        #print(xvalid.shape,xtrain.shape)\n",
    "        #print(tvalid)\n",
    "        #pars='-t 3 -g '+str(i)\n",
    "        print(pars)\n",
    "        model = svm_train(ttrain, xtrain ,pars )\n",
    "        start_time = time.time()\n",
    "        p_labs, p_acc, p_vals = svm_predict(tvalid, xvalid, model )\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        accuracy.append(p_acc[0])\n",
    "\n",
    "    print('Number of batches',k)\n",
    "    #print('Number of samples are', 10)\n",
    "    #print('gamma value is',2)\n",
    "    print('final accuracy',np.mean(accuracy))\n",
    "    acc_val.append(np.mean(accuracy))\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(vals,acc_val,marker='o',label='accuracy')\n",
    "plt.title('accuracy vs value of gamma')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159551a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46c6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
